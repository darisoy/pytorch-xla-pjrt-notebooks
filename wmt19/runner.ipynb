{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install nightly PyTorch/XLA\n",
    "# %pip install --user https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch-nightly-cp38-cp38-linux_x86_64.whl https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torchvision-nightly-cp38-cp38-linux_x86_64.whl 'torch_xla[tpuvm] @ https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch_xla-nightly-cp38-cp38-linux_x86_64.whl'\n",
    "# %pip install datasets transformers sacremoses evaluate sklearn sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important note\n",
    "DO NOT access the TPU on this file. ex dont:\n",
    "`xm.get_xla_supported_devices(\"TPU\")`\n",
    "\n",
    "if the TPU is accessed and this file can't run, kill the TPU processes:\n",
    "`$ lsof -t /dev/accel* | xargs kill`\n",
    "\n",
    "#### Why?\n",
    "For now `start_method='fork'` parameter of `xmp.spawn` isn't implemented for PjRt so `xmp.spawn` amd `mp_fn` functions have to live in seperate notebook files. This [StackOverflow answer](https://stackoverflow.com/a/42383397/13272853) explains the fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.wmt19 import mp_fn\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import os\n",
    "os.environ['PJRT_DEVICE'] = 'TPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "FLAGS = {}\n",
    "FLAGS['batch_size'] = 4\n",
    "FLAGS['num_workers'] = 4\n",
    "FLAGS['learning_rate'] = 5e-5\n",
    "FLAGS['num_epochs'] = 3\n",
    "FLAGS['num_cores'] = 8\n",
    "FLAGS['log_steps'] = 20\n",
    "FLAGS['metrics_debug'] = False\n",
    "FLAGS['source_lang'] = \"de\"\n",
    "FLAGS['target_lang'] = \"en\"\n",
    "FLAGS['metrics_debug'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset news_commentary (/home/darisoy/.cache/huggingface/datasets/news_commentary/de-en/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "WARNING:datasets.builder:Found cached dataset news_commentary (/home/darisoy/.cache/huggingface/datasets/news_commentary/de-en/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "WARNING:datasets.builder:Found cached dataset news_commentary (/home/darisoy/.cache/huggingface/datasets/news_commentary/de-en/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "WARNING:datasets.builder:Found cached dataset news_commentary (/home/darisoy/.cache/huggingface/datasets/news_commentary/de-en/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "100%|██████████| 224/224 [04:02<00:00,  1.08s/ba]\n",
      "100%|██████████| 224/224 [04:07<00:00,  1.11s/ba]\n",
      "100%|██████████| 224/224 [04:09<00:00,  1.11s/ba]\n",
      " 99%|█████████▉| 222/224 [04:10<00:02,  1.13s/ba]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [04:11<00:00,  1.12s/ba]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[xla:3](0) Loss=12.24021 Rate=0.16 GlobalRate=0.16 Time=Fri Nov 18 19:04:48 2022\n",
      "[xla:2](0) Loss=12.23144 Rate=0.18 GlobalRate=0.18 Time=Fri Nov 18 19:04:53 2022\n",
      "[xla:0](0) Loss=12.20990 Rate=0.16 GlobalRate=0.16 Time=Fri Nov 18 19:04:56 2022\n",
      "[xla:1](0) Loss=12.28506 Rate=0.17 GlobalRate=0.17 Time=Fri Nov 18 19:04:57 2022\n",
      "[xla:2](20) Loss=3.51296 Rate=0.11 GlobalRate=0.07 Time=Fri Nov 18 19:24:31 2022\n",
      "[xla:1](20) Loss=3.38993 Rate=0.11 GlobalRate=0.07 Time=Fri Nov 18 19:24:31 2022\n",
      "[xla:0](20) Loss=3.41230 Rate=0.10 GlobalRate=0.07 Time=Fri Nov 18 19:24:31 2022\n",
      "[xla:3](20) Loss=3.41096 Rate=0.11 GlobalRate=0.07 Time=Fri Nov 18 19:24:31 2022\n",
      "[xla:0](40) Loss=0.22357 Rate=5.06 GlobalRate=0.14 Time=Fri Nov 18 19:24:41 2022\n",
      "[xla:2](40) Loss=0.17255 Rate=5.05 GlobalRate=0.14 Time=Fri Nov 18 19:24:41 2022\n",
      "[xla:3](40) Loss=0.19732 Rate=5.06 GlobalRate=0.13 Time=Fri Nov 18 19:24:41 2022\n",
      "[xla:1](40) Loss=0.19955 Rate=5.03 GlobalRate=0.14 Time=Fri Nov 18 19:24:41 2022\n",
      "[xla:3](60) Loss=0.13260 Rate=7.04 GlobalRate=0.20 Time=Fri Nov 18 19:24:51 2022\n",
      "[xla:2](60) Loss=0.32970 Rate=7.01 GlobalRate=0.20 Time=Fri Nov 18 19:24:51 2022\n",
      "[xla:1](60) Loss=0.12422 Rate=7.02 GlobalRate=0.20 Time=Fri Nov 18 19:24:51 2022\n",
      "[xla:0](60) Loss=0.20423 Rate=7.00 GlobalRate=0.20 Time=Fri Nov 18 19:24:51 2022\n",
      "Finished training epoch 1\n",
      "Evaluate epoch 1\n",
      "[xla:1] Bleu=4.37569 Time=Fri Nov 18 19:27:10 2022\n",
      "[xla:1](0) Loss=0.10978 Rate=0.99 GlobalRate=0.99 Time=Fri Nov 18 19:27:14 2022\n",
      "[xla:3] Bleu=3.96163 Time=Fri Nov 18 19:27:20 2022\n",
      "[xla:2] Bleu=4.32557 Time=Fri Nov 18 19:27:21 2022\n",
      "[xla:3](0) Loss=0.11145 Rate=1.00 GlobalRate=1.00 Time=Fri Nov 18 19:27:24 2022\n",
      "[xla:2](0) Loss=0.08758 Rate=1.10 GlobalRate=1.10 Time=Fri Nov 18 19:27:24 2022\n",
      "[xla:0] Bleu=4.26996 Time=Fri Nov 18 19:27:27 2022\n",
      "Started training epoch 2\n",
      "[xla:0](0) Loss=0.14410 Rate=1.14 GlobalRate=1.14 Time=Fri Nov 18 19:27:30 2022\n",
      "[xla:0](20) Loss=0.11662 Rate=5.33 GlobalRate=6.30 Time=Fri Nov 18 19:27:40 2022\n",
      "[xla:1](20) Loss=0.06593 Rate=2.23 GlobalRate=2.78 Time=Fri Nov 18 19:27:40 2022\n",
      "[xla:2](20) Loss=0.24142 Rate=3.54 GlobalRate=4.40 Time=Fri Nov 18 19:27:40 2022\n",
      "[xla:3](20) Loss=0.11217 Rate=3.32 GlobalRate=4.11 Time=Fri Nov 18 19:27:40 2022\n",
      "[xla:0](40) Loss=0.14997 Rate=6.81 GlobalRate=6.95 Time=Fri Nov 18 19:27:50 2022\n",
      "[xla:2](40) Loss=0.11548 Rate=6.11 GlobalRate=5.59 Time=Fri Nov 18 19:27:50 2022\n",
      "[xla:1](40) Loss=0.13470 Rate=5.56 GlobalRate=4.05 Time=Fri Nov 18 19:27:50 2022\n",
      "[xla:3](40) Loss=0.12767 Rate=6.10 GlobalRate=5.38 Time=Fri Nov 18 19:27:50 2022\n",
      "[xla:2](60) Loss=0.27870 Rate=7.21 GlobalRate=6.19 Time=Fri Nov 18 19:28:00 2022\n",
      "[xla:1](60) Loss=0.10204 Rate=7.01 GlobalRate=4.83 Time=Fri Nov 18 19:28:00 2022\n",
      "[xla:3](60) Loss=0.10485 Rate=7.23 GlobalRate=6.03 Time=Fri Nov 18 19:28:00 2022\n",
      "[xla:0](60) Loss=0.19878 Rate=7.47 GlobalRate=7.24 Time=Fri Nov 18 19:28:00 2022\n",
      "Finished training epoch 2\n",
      "Evaluate epoch 2\n",
      "[xla:1] Bleu=4.27897 Time=Fri Nov 18 19:29:31 2022\n",
      "[xla:2] Bleu=4.66585 Time=Fri Nov 18 19:29:31 2022\n",
      "[xla:3] Bleu=4.19111 Time=Fri Nov 18 19:29:34 2022\n",
      "[xla:1](0) Loss=0.09293 Rate=1.06 GlobalRate=1.06 Time=Fri Nov 18 19:29:34 2022\n",
      "[xla:0] Bleu=4.77869 Time=Fri Nov 18 19:29:35 2022\n",
      "Started training epoch 3\n",
      "[xla:2](0) Loss=0.08991 Rate=1.03 GlobalRate=1.03 Time=Fri Nov 18 19:29:35 2022\n",
      "[xla:3](0) Loss=0.10926 Rate=1.19 GlobalRate=1.19 Time=Fri Nov 18 19:29:37 2022\n",
      "[xla:0](0) Loss=0.13869 Rate=1.12 GlobalRate=1.12 Time=Fri Nov 18 19:29:38 2022\n",
      "[xla:0](20) Loss=0.10217 Rate=5.42 GlobalRate=6.35 Time=Fri Nov 18 19:29:48 2022\n",
      "[xla:1](20) Loss=0.06295 Rate=4.01 GlobalRate=4.89 Time=Fri Nov 18 19:29:48 2022\n",
      "[xla:3](20) Loss=0.09730 Rate=5.03 GlobalRate=6.04 Time=Fri Nov 18 19:29:48 2022\n",
      "[xla:2](20) Loss=0.21908 Rate=4.08 GlobalRate=4.95 Time=Fri Nov 18 19:29:48 2022\n",
      "[xla:1](40) Loss=0.11333 Rate=6.44 GlobalRate=6.06 Time=Fri Nov 18 19:29:58 2022\n",
      "[xla:3](40) Loss=0.10931 Rate=6.85 GlobalRate=6.88 Time=Fri Nov 18 19:29:58 2022\n",
      "[xla:2](40) Loss=0.09582 Rate=6.47 GlobalRate=6.10 Time=Fri Nov 18 19:29:58 2022\n",
      "[xla:0](40) Loss=0.13548 Rate=6.97 GlobalRate=7.06 Time=Fri Nov 18 19:29:58 2022\n",
      "[xla:1](60) Loss=0.09898 Rate=7.58 GlobalRate=6.66 Time=Fri Nov 18 19:30:07 2022\n",
      "[xla:3](60) Loss=0.09532 Rate=7.75 GlobalRate=7.31 Time=Fri Nov 18 19:30:07 2022\n",
      "[xla:2](60) Loss=0.25770 Rate=7.57 GlobalRate=6.68 Time=Fri Nov 18 19:30:07 2022\n",
      "[xla:0](60) Loss=0.15848 Rate=7.79 GlobalRate=7.44 Time=Fri Nov 18 19:30:07 2022\n",
      "Finished training epoch 3\n",
      "Evaluate epoch 3\n",
      "[xla:1] Bleu=4.74747 Time=Fri Nov 18 19:38:08 2022\n",
      "[xla:2] Bleu=5.03644 Time=Fri Nov 18 19:38:08 2022\n",
      "[xla:3] Bleu=4.49289 Time=Fri Nov 18 19:38:10 2022\n",
      "[xla:0] Bleu=5.01748 Time=Fri Nov 18 19:38:11 2022\n"
     ]
    }
   ],
   "source": [
    "# Start the training\n",
    "xmp.spawn(mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'], start_method='fork')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
