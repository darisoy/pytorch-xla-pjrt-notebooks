{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install nightly PyTorch/XLA\n",
    "# %pip install --user https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch-nightly-cp38-cp38-linux_x86_64.whl https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torchvision-nightly-cp38-cp38-linux_x86_64.whl 'torch_xla[tpuvm] @ https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch_xla-nightly-cp38-cp38-linux_x86_64.whl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important note\n",
    "DO NOT access the TPU on this file. ex dont:\n",
    "`xm.get_xla_supported_devices(\"TPU\")`\n",
    "\n",
    "if the TPU is accessed and this file can't run, kill the TPU processes:\n",
    "`$ lsof -t /dev/accel* | xargs kill`\n",
    "\n",
    "#### Why?\n",
    "For now `start_method='fork'` parameter of `xmp.spawn` isn't implemented for PjRt so `xmp.spawn` amd `mp_fn` functions have to live in seperate notebook files. This [StackOverflow answer](https://stackoverflow.com/a/42383397/13272853) explains the fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.wmt19 import mp_fn #pip install ipynb\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import os\n",
    "os.environ['PJRT_DEVICE'] = 'TPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "FLAGS = {}\n",
    "FLAGS['batch_size'] = 4\n",
    "FLAGS['num_workers'] = 4\n",
    "FLAGS['learning_rate'] = 5e-5\n",
    "FLAGS['num_epochs'] = 3\n",
    "FLAGS['num_cores'] = 8\n",
    "FLAGS['log_steps'] = 1\n",
    "FLAGS['metrics_debug'] = False\n",
    "FLAGS['source_lang'] = \"de\"\n",
    "FLAGS['target_lang'] = \"en\"\n",
    "FLAGS['metrics_debug'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset news_commentary (/home/darisoy/.cache/huggingface/datasets/news_commentary/de-en/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "WARNING:datasets.builder:Found cached dataset news_commentary (/home/darisoy/.cache/huggingface/datasets/news_commentary/de-en/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "WARNING:datasets.builder:Found cached dataset news_commentary (/home/darisoy/.cache/huggingface/datasets/news_commentary/de-en/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "WARNING:datasets.builder:Found cached dataset news_commentary (/home/darisoy/.cache/huggingface/datasets/news_commentary/de-en/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "100%|██████████| 224/224 [04:10<00:00,  1.12s/ba]\n",
      "100%|██████████| 224/224 [04:11<00:00,  1.12s/ba]\n",
      "100%|██████████| 224/224 [04:15<00:00,  1.14s/ba]\n",
      "100%|██████████| 224/224 [04:18<00:00,  1.15s/ba]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "To be able to use evaluate-metric/accuracy, you need to install the following dependencies['sklearn'] using 'pip install sklearn' for instance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 239, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 198, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 198, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/torch_xla/experimental/pjrt.py\", line 59, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/torch_xla/experimental/pjrt.py\", line 188, in _run_thread_per_device\n    replica_results = list(\n  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 619, in result_iterator\n    yield fs.pop().result()\n  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n    return self.__get_result()\n  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n    raise self._exception\n  File \"/usr/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/torch_xla/experimental/pjrt.py\", line 180, in _thread_fn\n    return fn()\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/torch_xla/experimental/pjrt.py\", line 239, in __call__\n    self.fn(global_ordinal(), *self.args, **self.kwargs)\n  File \"/home/darisoy/pytorch-xla-pjrt-notebooks/wmt19-de-en/wmt19.ipynb\", line 205, in mp_fn\n    \"import torch\\n\",\n  File \"/home/darisoy/pytorch-xla-pjrt-notebooks/wmt19-de-en/wmt19.ipynb\", line 197, in finetune\n    {\n  File \"/home/darisoy/pytorch-xla-pjrt-notebooks/wmt19-de-en/wmt19.ipynb\", line 176, in test_loop_fn\n    {\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/evaluate/loading.py\", line 716, in load\n    evaluation_module = evaluation_module_factory(\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/evaluate/loading.py\", line 665, in evaluation_module_factory\n    raise e1 from None\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/evaluate/loading.py\", line 632, in evaluation_module_factory\n    return HubEvaluationModuleFactory(\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/evaluate/loading.py\", line 492, in get_module\n    local_imports = _download_additional_modules(\n  File \"/home/darisoy/.local/lib/python3.8/site-packages/evaluate/loading.py\", line 268, in _download_additional_modules\n    raise ImportError(\nImportError: To be able to use evaluate-metric/accuracy, you need to install the following dependencies['sklearn'] using 'pip install sklearn' for instance'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Start the training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m xmp\u001b[39m.\u001b[39;49mspawn(mp_fn, args\u001b[39m=\u001b[39;49m(FLAGS,), nprocs\u001b[39m=\u001b[39;49mFLAGS[\u001b[39m'\u001b[39;49m\u001b[39mnum_cores\u001b[39;49m\u001b[39m'\u001b[39;49m], start_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfork\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_xla/distributed/xla_multiprocessing.py:389\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39m\"\"\"Enables multi processing based replication.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \n\u001b[1;32m    365\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39m  return None.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m pjrt\u001b[39m.\u001b[39musing_pjrt():\n\u001b[0;32m--> 389\u001b[0m   \u001b[39mreturn\u001b[39;00m pjrt\u001b[39m.\u001b[39;49mspawn(fn, args)\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_xla_config():\n\u001b[1;32m    392\u001b[0m   \u001b[39m# If this is not an XLA setup, jump to normal multi-processing.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m   \u001b[39mreturn\u001b[39;00m _run_direct(fn, args, nprocs, join, daemon, start_method)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_xla/experimental/pjrt.py:250\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m\"\"\"Run functions compatible with xmp.spawn.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m  fn: Callable that takes the process index as the first argument.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m  args: args to pass to `fn`\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m spawn_fn \u001b[39m=\u001b[39m _SpawnFn(fn, \u001b[39m*\u001b[39margs)\n\u001b[0;32m--> 250\u001b[0m _run_multiprocess(spawn_fn)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_xla/experimental/pjrt.py:59\u001b[0m, in \u001b[0;36mrequires_pjrt.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m using_pjrt():\n\u001b[1;32m     56\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m` not implemented for XRT\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     57\u001b[0m       fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[0;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_xla/experimental/pjrt.py:223\u001b[0m, in \u001b[0;36m_run_multiprocess\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m   mp_fn \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    219\u001b[0m       _run_thread_per_device,\n\u001b[1;32m    220\u001b[0m       local_world_size\u001b[39m=\u001b[39mnum_processes,\n\u001b[1;32m    221\u001b[0m       fn\u001b[39m=\u001b[39mfunctools\u001b[39m.\u001b[39mpartial(fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[1;32m    222\u001b[0m   process_results \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39mmap(mp_fn, \u001b[39mrange\u001b[39m(num_processes))\n\u001b[0;32m--> 223\u001b[0m   replica_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m    224\u001b[0m       itertools\u001b[39m.\u001b[39;49mchain\u001b[39m.\u001b[39;49mfrom_iterable(\n\u001b[1;32m    225\u001b[0m           result\u001b[39m.\u001b[39;49mitems() \u001b[39mfor\u001b[39;49;00m result \u001b[39min\u001b[39;49;00m process_results))\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m _merge_replica_results(replica_results)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_xla/experimental/pjrt.py:224\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    218\u001b[0m   mp_fn \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    219\u001b[0m       _run_thread_per_device,\n\u001b[1;32m    220\u001b[0m       local_world_size\u001b[39m=\u001b[39mnum_processes,\n\u001b[1;32m    221\u001b[0m       fn\u001b[39m=\u001b[39mfunctools\u001b[39m.\u001b[39mpartial(fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[1;32m    222\u001b[0m   process_results \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39mmap(mp_fn, \u001b[39mrange\u001b[39m(num_processes))\n\u001b[1;32m    223\u001b[0m   replica_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m--> 224\u001b[0m       itertools\u001b[39m.\u001b[39mchain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m    225\u001b[0m           result\u001b[39m.\u001b[39mitems() \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m process_results))\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m _merge_replica_results(replica_results)\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/process.py:484\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    479\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    485\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    486\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39;49mpop()\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39mpop()\u001b[39m.\u001b[39mresult(end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    445\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: To be able to use evaluate-metric/accuracy, you need to install the following dependencies['sklearn'] using 'pip install sklearn' for instance'"
     ]
    }
   ],
   "source": [
    "# Start the training\n",
    "xmp.spawn(mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'], start_method='fork')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
